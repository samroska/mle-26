{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The following notebook outlines the process that one of our data scientists utilized to build a \"segmentation\" model for our marketing department.  The dependent variable is whether a customer purchased a product (y=1).or not (y=0). The implemented model will help the marketing department decide which customers receive an advertisement for the product.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statsmodels.api as sm\n",
    "#loading visualization library\n",
    "import bokeh\n",
    "\n",
    "import collections as ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.10.6 (main, Aug 30 2022, 04:58:14) [Clang 13.1.6 (clang-1316.0.21.2.5)]\n",
      "numpy version 1.23.3\n",
      "pandas version 1.4.4\n",
      "sklern version 0.23.1\n",
      "bokeh version 2.4.3\n",
      "statsmodels version 0.9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"python version \" + sys.version)\n",
    "print('numpy version ' + np.__version__)\n",
    "print('pandas version ' + pd.__version__)\n",
    "print('sklern version ' + '0.23.1')\n",
    "print('bokeh version ' + bokeh.__version__)\n",
    "print('statsmodels version ' + '0.9.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 19904, 0: 20096})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train=pd.read_csv('exercise_26_train.csv')\n",
    "raw_test=pd.read_csv('exercise_26_test.csv')\n",
    "#Desribing the target variable\n",
    "from collections import Counter\n",
    "Counter(raw_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object dtype: ['x5', 'x12', 'x31', 'x63', 'x81', 'x82']\n",
      "int64 dtype: ['y']\n",
      "The rest of the columns have float64 dtypes.\n"
     ]
    }
   ],
   "source": [
    "# Overview of data types\n",
    "print(\"object dtype:\", raw_train.columns[raw_train.dtypes == 'object'].tolist())\n",
    "print(\"int64 dtype:\", raw_train.columns[raw_train.dtypes == 'int'].tolist())\n",
    "print(\"The rest of the columns have float64 dtypes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x5: Unique Values: ['tuesday' 'saturday' 'thursday' 'sunday' 'wednesday' 'monday' 'friday']\n",
      "x12: Unique Values: ['$6,882.34 ' '$5,647.81 ' '($5,032.58)' '($1,920.03)' '($5,859.08)'\n",
      " '$8,535.02 ' '$66.55 ' '$2,421.58 ' '($2,586.99)' '($4,324.44)'\n",
      " '($8,015.98)' '$2,669.04 ' '$1,729.51 ' '...']\n",
      "x31: Unique Values: ['germany' 'asia' 'america' 'japan' nan]\n",
      "x63: Unique Values: ['62.59%' '3.11%' '28.07%' '33.49%' '88.73%' '11.05%' '89.23%' '69.48%'\n",
      " '35.15%' '67.12%' '90.90%' '60.46%' '68.56%' '...']\n",
      "x81: Unique Values: ['April' 'December' 'May' 'November' 'March' 'June' 'July' 'October'\n",
      " 'January' 'February' 'August' 'September']\n",
      "x82: Unique Values: ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Investigate Object Columns\n",
    "def investigate_object(df):\n",
    "    \"\"\"\n",
    "    This function prints the unique categories of all the object dtype columns.\n",
    "    It prints '...' if there are more than 13 unique categories.\n",
    "    \"\"\"\n",
    "    col_obj = df.columns[df.dtypes == 'object']\n",
    "\n",
    "    for i in range(len(col_obj)):\n",
    "        if len(df[col_obj[i]].unique()) > 13:\n",
    "            print(col_obj[i]+\":\", \"Unique Values:\", np.append(df[col_obj[i]].unique()[:13], \"...\"))\n",
    "        else:\n",
    "            print(col_obj[i]+\":\", \"Unique Values:\", df[col_obj[i]].unique())\n",
    "    \n",
    "    del col_obj\n",
    "investigate_object(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/sj1qf7k94mb1p4hpvsb0mv880000gn/T/ipykernel_73192/1717917025.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_val['x12'] = train_val['x12'].str.replace('$','')\n",
      "/var/folders/76/sj1qf7k94mb1p4hpvsb0mv880000gn/T/ipykernel_73192/1717917025.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_val['x12'] = train_val['x12'].str.replace(')','')\n",
      "/var/folders/76/sj1qf7k94mb1p4hpvsb0mv880000gn/T/ipykernel_73192/1717917025.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  train_val['x12'] = train_val['x12'].str.replace('(','-')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.675304</td>\n",
       "      <td>0.137379</td>\n",
       "      <td>4.393917</td>\n",
       "      <td>-0.020123</td>\n",
       "      <td>-0.475619</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0.157397</td>\n",
       "      <td>55.677997</td>\n",
       "      <td>1.836050</td>\n",
       "      <td>0.918460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406396</td>\n",
       "      <td>0.923903</td>\n",
       "      <td>3.190372</td>\n",
       "      <td>-99.480414</td>\n",
       "      <td>0.658721</td>\n",
       "      <td>1.017211</td>\n",
       "      <td>0.841947</td>\n",
       "      <td>-32.135482</td>\n",
       "      <td>-92.817959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.154193</td>\n",
       "      <td>0.491916</td>\n",
       "      <td>6.224052</td>\n",
       "      <td>0.911310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thursday</td>\n",
       "      <td>0.322901</td>\n",
       "      <td>67.982758</td>\n",
       "      <td>3.558598</td>\n",
       "      <td>0.968550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213260</td>\n",
       "      <td>0.691155</td>\n",
       "      <td>3.513803</td>\n",
       "      <td>-102.807379</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>1.523666</td>\n",
       "      <td>0.625777</td>\n",
       "      <td>-32.038531</td>\n",
       "      <td>-111.458616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517891</td>\n",
       "      <td>5.329731</td>\n",
       "      <td>3.356213</td>\n",
       "      <td>-0.311618</td>\n",
       "      <td>-1.251960</td>\n",
       "      <td>saturday</td>\n",
       "      <td>0.429534</td>\n",
       "      <td>79.291691</td>\n",
       "      <td>3.668720</td>\n",
       "      <td>0.484290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092073</td>\n",
       "      <td>0.984555</td>\n",
       "      <td>3.275413</td>\n",
       "      <td>-104.647167</td>\n",
       "      <td>1.114742</td>\n",
       "      <td>0.629985</td>\n",
       "      <td>0.443220</td>\n",
       "      <td>-32.529417</td>\n",
       "      <td>96.050527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.387908</td>\n",
       "      <td>3.731997</td>\n",
       "      <td>3.860884</td>\n",
       "      <td>-1.062690</td>\n",
       "      <td>-0.170879</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0.673016</td>\n",
       "      <td>62.361178</td>\n",
       "      <td>4.003594</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022378</td>\n",
       "      <td>0.518466</td>\n",
       "      <td>3.161572</td>\n",
       "      <td>-103.345848</td>\n",
       "      <td>0.116029</td>\n",
       "      <td>1.979604</td>\n",
       "      <td>0.658648</td>\n",
       "      <td>-32.175854</td>\n",
       "      <td>75.606195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079124</td>\n",
       "      <td>-1.802406</td>\n",
       "      <td>5.183612</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.636439</td>\n",
       "      <td>friday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.093272</td>\n",
       "      <td>4.263777</td>\n",
       "      <td>0.405445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124459</td>\n",
       "      <td>0.364577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.521508</td>\n",
       "      <td>1.056957</td>\n",
       "      <td>1.293643</td>\n",
       "      <td>0.243751</td>\n",
       "      <td>-32.564535</td>\n",
       "      <td>21.057102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0 -0.675304  0.137379  4.393917 -0.020123 -0.475619    sunday  0.157397   \n",
       "1 -1.154193  0.491916  6.224052  0.911310       NaN  thursday  0.322901   \n",
       "2 -0.517891  5.329731  3.356213 -0.311618 -1.251960  saturday  0.429534   \n",
       "3 -1.387908  3.731997  3.860884 -1.062690 -0.170879    sunday  0.673016   \n",
       "4  0.079124 -1.802406  5.183612  0.801429  0.636439    friday       NaN   \n",
       "\n",
       "          x7        x8        x9  ...       x91       x92       x93  \\\n",
       "0  55.677997  1.836050  0.918460  ...  0.406396  0.923903  3.190372   \n",
       "1  67.982758  3.558598  0.968550  ... -0.213260  0.691155  3.513803   \n",
       "2  79.291691  3.668720  0.484290  ... -0.092073  0.984555  3.275413   \n",
       "3  62.361178  4.003594  0.976110  ... -0.022378  0.518466  3.161572   \n",
       "4  42.093272  4.263777  0.405445  ... -0.124459  0.364577       NaN   \n",
       "\n",
       "          x94       x95       x96       x97        x98         x99  y  \n",
       "0  -99.480414  0.658721  1.017211  0.841947 -32.135482  -92.817959  1  \n",
       "1 -102.807379  0.855491  1.523666  0.625777 -32.038531 -111.458616  0  \n",
       "2 -104.647167  1.114742  0.629985  0.443220 -32.529417   96.050527  0  \n",
       "3 -103.345848  0.116029  1.979604  0.658648 -32.175854   75.606195  0  \n",
       "4  -90.521508  1.056957  1.293643  0.243751 -32.564535   21.057102  1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = raw_train.copy(deep=True)\n",
    "\n",
    "#1. Fixing the money and percents#\n",
    "train_val['x12'] = train_val['x12'].str.replace('$','')\n",
    "train_val['x12'] = train_val['x12'].str.replace(',','')\n",
    "train_val['x12'] = train_val['x12'].str.replace(')','')\n",
    "train_val['x12'] = train_val['x12'].str.replace('(','-')\n",
    "train_val['x12'] = train_val['x12'].astype(float)\n",
    "train_val['x63'] = train_val['x63'].str.replace('%','')\n",
    "train_val['x63'] = train_val['x63'].astype(float)\n",
    "\n",
    "# 2. Creating the train/val/test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_val.drop(columns=['y']), train_val['y'], test_size=0.1, random_state=13)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=4000, random_state=13)\n",
    "\n",
    "# 3. smashing sets back together\n",
    "train = pd.concat([x_train, y_train], axis=1, sort=False).reset_index(drop=True)\n",
    "val = pd.concat([x_val, y_val], axis=1, sort=False).reset_index(drop=True)\n",
    "test = pd.concat([x_test, y_test], axis=1, sort=False).reset_index(drop=True)\n",
    "\n",
    "# 3. With mean imputation from Train set\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "train_imputed = pd.DataFrame(imputer.fit_transform(train.drop(columns=['y', 'x5', 'x31',  'x81' ,'x82'])), columns=train.drop(columns=['y', 'x5', 'x31', 'x81', 'x82']).columns)\n",
    "std_scaler = StandardScaler()\n",
    "train_imputed_std = pd.DataFrame(std_scaler.fit_transform(train_imputed), columns=train_imputed.columns)\n",
    "\n",
    "# 3 create dummies\n",
    "\n",
    "dumb5 = pd.get_dummies(train['x5'], drop_first=True, prefix='x5', prefix_sep='_', dummy_na=True)\n",
    "train_imputed_std = pd.concat([train_imputed_std, dumb5], axis=1, sort=False)\n",
    "\n",
    "dumb31 = pd.get_dummies(train['x31'], drop_first=True, prefix='x31', prefix_sep='_', dummy_na=True)\n",
    "train_imputed_std = pd.concat([train_imputed_std, dumb31], axis=1, sort=False)\n",
    "\n",
    "dumb81 = pd.get_dummies(train['x81'], drop_first=True, prefix='x81', prefix_sep='_', dummy_na=True)\n",
    "train_imputed_std = pd.concat([train_imputed_std, dumb81], axis=1, sort=False)\n",
    "\n",
    "dumb82 = pd.get_dummies(train['x82'], drop_first=True, prefix='x82', prefix_sep='_', dummy_na=True)\n",
    "train_imputed_std = pd.concat([train_imputed_std, dumb82], axis=1, sort=False)\n",
    "train_imputed_std = pd.concat([train_imputed_std, train['y']], axis=1, sort=False)\n",
    "\n",
    "del dumb5, dumb31, dumb81, dumb82\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.92229931e-04, -1.00645489e-02,  4.99964676e+00,  1.41831121e-03,\n",
       "        4.93924244e-03,  5.00363576e-01,  5.00408689e+01,  2.50906048e+00,\n",
       "        4.98037746e-01,  1.44968823e+01, -1.00062564e+00,  2.04852884e+01,\n",
       "        4.99312723e-01,  2.49398483e+01,  5.21042421e-01,  4.98721665e-01,\n",
       "        1.45017479e+01, -2.00022871e+01,  4.98149710e-01,  1.24833757e-01,\n",
       "       -3.51584541e-02,  5.01571313e-01,  3.50017149e+00, -9.99264396e+01,\n",
       "        7.51218322e-01,  2.50959339e+00,  4.99573809e-01,  1.45005206e+01,\n",
       "       -1.00944689e+00,  5.00258855e+00,  4.99455396e-01,  2.50064264e+00,\n",
       "       -1.60173697e+00,  9.48489867e-01, -5.00485651e-01,  3.50071828e+00,\n",
       "       -1.50197839e+00, -1.00357228e+00,  1.54335146e+00,  1.52266682e+01,\n",
       "        5.17458033e+00,  8.60583320e+00,  5.00565465e-01, -8.25609536e-04,\n",
       "       -2.43701265e-03,  2.89563910e-03, -1.88721614e-03, -2.45598108e-03,\n",
       "       -2.46846377e-03,  2.87215906e-03, -7.76626320e-03,  4.00117940e-01,\n",
       "        1.85134565e-03, -3.81337547e-03, -1.08785921e-02, -1.07373755e-03,\n",
       "        2.38947031e-03, -1.32876809e-02, -1.00956638e-02,  1.17362322e-02,\n",
       "        7.20015114e-03,  5.01826641e+01,  2.49920237e+01,  4.85763644e-01,\n",
       "        5.00378940e-01,  1.45015466e+01, -1.99992495e+01,  4.99218322e-01,\n",
       "        1.25149089e-01, -2.00441246e-02,  5.00265753e-01,  3.50105294e+00,\n",
       "       -1.00035053e+02,  7.51146827e-01,  2.49194207e+00,  4.98352393e-01,\n",
       "        1.44987515e+01, -1.00548754e+00,  5.00418400e+00,  4.50796851e-03,\n",
       "       -7.80333551e-03,  1.05855350e-03,  7.28022416e-03, -5.78632309e-03,\n",
       "        3.54983718e-03,  9.46329051e-05,  2.12883666e-03,  2.52963305e-01,\n",
       "        5.00500633e-01,  3.50017350e+00, -1.00106443e+02,  7.45890997e-01,\n",
       "        1.49930930e+00,  5.02749055e-01, -3.24990379e+01, -4.89850862e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the imputer statistics\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0        1.009929\n",
       "x1        8.916178\n",
       "x2        0.988932\n",
       "x3        0.979721\n",
       "x4        0.973921\n",
       "          ...     \n",
       "x95       0.184415\n",
       "x96       0.721085\n",
       "x97       0.081038\n",
       "x98       0.082531\n",
       "x99    9914.189604\n",
       "Length: 96, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the variance\n",
    "train_imputed.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Correlations\n",
    "As part of the exploratory analysis, we want to look at a heatmap to see if there are any high pairwise correlations.  If we see a few number of variables correlated with the target, then we will use an L2 penalty.  If we see a lot of variables correlated with y then we will use an L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(\"matplotlib version \" + matplotlib.__version__)\n",
    "print(\"seaborn version \" + sns.__version__)\n",
    "sns.set(style='white')\n",
    "\n",
    "corr = train_imputed_std.corr()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(data=corr,\n",
    "            center=0,\n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
    "            square=True, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Feature Selection\n",
    "Looking at the correlation map from above, we can see there are very few variables associated with the dependent variable.  Thus, we will use an L1 penalty to for feature selection. Interestingly enough, we see a that some variables have heavy correlation amongst themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_LR = LogisticRegression(penalty='l1', fit_intercept=False, solver='liblinear')\n",
    "exploratory_LR.fit(train_imputed_std.drop(columns=['y']), train_imputed_std['y'])\n",
    "exploratory_results = pd.DataFrame(train_imputed_std.drop(columns=['y']).columns).rename(columns={0:'name'})\n",
    "exploratory_results['coefs'] = exploratory_LR.coef_[0]\n",
    "exploratory_results['coefs_squared'] = exploratory_results['coefs']**2\n",
    "var_reduced = exploratory_results.nlargest(25,'coefs_squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Model\n",
    "## Starting with the train set\n",
    "The L1 process creates biased parameter estimates.  As a result, we will build a final model without biased estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536381\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 32000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 31975</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 13 Sep 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.2262</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:58:00</td>     <th>  Log-Likelihood:    </th> <td> -17164.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -22181.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_saturday</th>   <td>   -1.1834</td> <td>    0.041</td> <td>  -29.039</td> <td> 0.000</td> <td>   -1.263</td> <td>   -1.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_July</th>      <td>    1.1139</td> <td>    0.053</td> <td>   20.893</td> <td> 0.000</td> <td>    1.009</td> <td>    1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_December</th>  <td>    1.0501</td> <td>    0.053</td> <td>   19.917</td> <td> 0.000</td> <td>    0.947</td> <td>    1.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_japan</th>     <td>    0.8994</td> <td>    0.062</td> <td>   14.413</td> <td> 0.000</td> <td>    0.777</td> <td>    1.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_October</th>   <td>    0.9262</td> <td>    0.052</td> <td>   17.783</td> <td> 0.000</td> <td>    0.824</td> <td>    1.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_sunday</th>     <td>   -0.8408</td> <td>    0.040</td> <td>  -21.038</td> <td> 0.000</td> <td>   -0.919</td> <td>   -0.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_asia</th>      <td>   -0.7802</td> <td>    0.033</td> <td>  -23.443</td> <td> 0.000</td> <td>   -0.845</td> <td>   -0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_February</th>  <td>    0.8670</td> <td>    0.052</td> <td>   16.658</td> <td> 0.000</td> <td>    0.765</td> <td>    0.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>           <td>    0.7682</td> <td>    0.014</td> <td>   54.253</td> <td> 0.000</td> <td>    0.740</td> <td>    0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_May</th>       <td>    0.8104</td> <td>    0.053</td> <td>   15.371</td> <td> 0.000</td> <td>    0.707</td> <td>    0.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_monday</th>     <td>   -0.7022</td> <td>    0.040</td> <td>  -17.632</td> <td> 0.000</td> <td>   -0.780</td> <td>   -0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_September</th> <td>    0.7231</td> <td>    0.052</td> <td>   13.877</td> <td> 0.000</td> <td>    0.621</td> <td>    0.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_March</th>     <td>    0.7081</td> <td>    0.052</td> <td>   13.531</td> <td> 0.000</td> <td>    0.606</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>           <td>   -0.6197</td> <td>    0.014</td> <td>  -44.860</td> <td> 0.000</td> <td>   -0.647</td> <td>   -0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_November</th>  <td>    0.5808</td> <td>    0.052</td> <td>   11.167</td> <td> 0.000</td> <td>    0.479</td> <td>    0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>           <td>   -0.5085</td> <td>    0.014</td> <td>  -37.333</td> <td> 0.000</td> <td>   -0.535</td> <td>   -0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_June</th>      <td>    0.4664</td> <td>    0.052</td> <td>    8.913</td> <td> 0.000</td> <td>    0.364</td> <td>    0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>           <td>   -0.3964</td> <td>    0.013</td> <td>  -29.531</td> <td> 0.000</td> <td>   -0.423</td> <td>   -0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_tuesday</th>    <td>   -0.3945</td> <td>    0.040</td> <td>   -9.950</td> <td> 0.000</td> <td>   -0.472</td> <td>   -0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_August</th>    <td>    0.4463</td> <td>    0.053</td> <td>    8.496</td> <td> 0.000</td> <td>    0.343</td> <td>    0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_January</th>   <td>    0.3726</td> <td>    0.052</td> <td>    7.121</td> <td> 0.000</td> <td>    0.270</td> <td>    0.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>           <td>   -0.2828</td> <td>    0.014</td> <td>  -20.604</td> <td> 0.000</td> <td>   -0.310</td> <td>   -0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_germany</th>   <td>   -0.1699</td> <td>    0.033</td> <td>   -5.157</td> <td> 0.000</td> <td>   -0.235</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>           <td>    0.2046</td> <td>    0.014</td> <td>   15.151</td> <td> 0.000</td> <td>    0.178</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>           <td>    0.1978</td> <td>    0.014</td> <td>   14.404</td> <td> 0.000</td> <td>    0.171</td> <td>    0.225</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                32000\n",
       "Model:                          Logit   Df Residuals:                    31975\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Tue, 13 Sep 2022   Pseudo R-squ.:                  0.2262\n",
       "Time:                        20:58:00   Log-Likelihood:                -17164.\n",
       "converged:                       True   LL-Null:                       -22181.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "x5_saturday      -1.1834      0.041    -29.039      0.000      -1.263      -1.104\n",
       "x81_July          1.1139      0.053     20.893      0.000       1.009       1.218\n",
       "x81_December      1.0501      0.053     19.917      0.000       0.947       1.153\n",
       "x31_japan         0.8994      0.062     14.413      0.000       0.777       1.022\n",
       "x81_October       0.9262      0.052     17.783      0.000       0.824       1.028\n",
       "x5_sunday        -0.8408      0.040    -21.038      0.000      -0.919      -0.762\n",
       "x31_asia         -0.7802      0.033    -23.443      0.000      -0.845      -0.715\n",
       "x81_February      0.8670      0.052     16.658      0.000       0.765       0.969\n",
       "x91               0.7682      0.014     54.253      0.000       0.740       0.796\n",
       "x81_May           0.8104      0.053     15.371      0.000       0.707       0.914\n",
       "x5_monday        -0.7022      0.040    -17.632      0.000      -0.780      -0.624\n",
       "x81_September     0.7231      0.052     13.877      0.000       0.621       0.825\n",
       "x81_March         0.7081      0.052     13.531      0.000       0.606       0.811\n",
       "x53              -0.6197      0.014    -44.860      0.000      -0.647      -0.593\n",
       "x81_November      0.5808      0.052     11.167      0.000       0.479       0.683\n",
       "x44              -0.5085      0.014    -37.333      0.000      -0.535      -0.482\n",
       "x81_June          0.4664      0.052      8.913      0.000       0.364       0.569\n",
       "x12              -0.3964      0.013    -29.531      0.000      -0.423      -0.370\n",
       "x5_tuesday       -0.3945      0.040     -9.950      0.000      -0.472      -0.317\n",
       "x81_August        0.4463      0.053      8.496      0.000       0.343       0.549\n",
       "x81_January       0.3726      0.052      7.121      0.000       0.270       0.475\n",
       "x62              -0.2828      0.014    -20.604      0.000      -0.310      -0.256\n",
       "x31_germany      -0.1699      0.033     -5.157      0.000      -0.235      -0.105\n",
       "x58               0.2046      0.014     15.151      0.000       0.178       0.231\n",
       "x56               0.1978      0.014     14.404      0.000       0.171       0.225\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = var_reduced['name'].to_list()\n",
    "logit = sm.Logit(train_imputed_std['y'], train_imputed_std[variables])\n",
    "# fit the model\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x81_June</th>\n",
       "      <th>x81_March</th>\n",
       "      <th>x81_May</th>\n",
       "      <th>x81_November</th>\n",
       "      <th>x81_October</th>\n",
       "      <th>x81_September</th>\n",
       "      <th>x81_nan</th>\n",
       "      <th>x82_Male</th>\n",
       "      <th>x82_nan</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.231911</td>\n",
       "      <td>0.186734</td>\n",
       "      <td>-0.438440</td>\n",
       "      <td>0.447099</td>\n",
       "      <td>-0.480048</td>\n",
       "      <td>1.413353</td>\n",
       "      <td>-1.203852</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>0.543303</td>\n",
       "      <td>1.425218</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.017748</td>\n",
       "      <td>-1.006176</td>\n",
       "      <td>0.543572</td>\n",
       "      <td>0.544661</td>\n",
       "      <td>-0.391593</td>\n",
       "      <td>-0.064206</td>\n",
       "      <td>-0.768629</td>\n",
       "      <td>-0.571327</td>\n",
       "      <td>0.177188</td>\n",
       "      <td>1.255437</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.370613</td>\n",
       "      <td>-0.483136</td>\n",
       "      <td>0.319564</td>\n",
       "      <td>0.115143</td>\n",
       "      <td>-0.164072</td>\n",
       "      <td>1.150836</td>\n",
       "      <td>1.707546</td>\n",
       "      <td>1.392168</td>\n",
       "      <td>-0.986833</td>\n",
       "      <td>0.396749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.416365</td>\n",
       "      <td>-0.400150</td>\n",
       "      <td>0.874787</td>\n",
       "      <td>-1.184976</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>-0.825217</td>\n",
       "      <td>-0.961963</td>\n",
       "      <td>0.236944</td>\n",
       "      <td>1.588518</td>\n",
       "      <td>-0.142784</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.083974</td>\n",
       "      <td>0.388143</td>\n",
       "      <td>0.799889</td>\n",
       "      <td>1.336362</td>\n",
       "      <td>1.258094</td>\n",
       "      <td>1.453268</td>\n",
       "      <td>0.348362</td>\n",
       "      <td>1.704476</td>\n",
       "      <td>-0.577322</td>\n",
       "      <td>-0.503365</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x6        x7  \\\n",
       "0 -0.231911  0.186734 -0.438440  0.447099 -0.480048  1.413353 -1.203852   \n",
       "1  1.017748 -1.006176  0.543572  0.544661 -0.391593 -0.064206 -0.768629   \n",
       "2 -1.370613 -0.483136  0.319564  0.115143 -0.164072  1.150836  1.707546   \n",
       "3  0.416365 -0.400150  0.874787 -1.184976 -0.109468 -0.825217 -0.961963   \n",
       "4  1.083974  0.388143  0.799889  1.336362  1.258094  1.453268  0.348362   \n",
       "\n",
       "         x8        x9       x10  ...  x81_June  x81_March  x81_May  \\\n",
       "0 -0.506744  0.543303  1.425218  ...         0          0        0   \n",
       "1 -0.571327  0.177188  1.255437  ...         0          0        0   \n",
       "2  1.392168 -0.986833  0.396749  ...         0          0        0   \n",
       "3  0.236944  1.588518 -0.142784  ...         0          0        1   \n",
       "4  1.704476 -0.577322 -0.503365  ...         0          1        0   \n",
       "\n",
       "   x81_November  x81_October  x81_September  x81_nan  x82_Male  x82_nan  y  \n",
       "0             0            0              0        0         0        0  1  \n",
       "1             0            0              0        0         0        0  0  \n",
       "2             0            1              0        0         0        0  1  \n",
       "3             0            0              0        0         0        0  0  \n",
       "4             0            0              0        0         1        0  1  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_imputed = pd.DataFrame(imputer.transform(val.drop(columns=['y', 'x5', 'x31', 'x81' ,'x82'])), columns=train.drop(columns=['y','x5', 'x31', 'x81', 'x82']).columns)\n",
    "val_imputed_std = pd.DataFrame(std_scaler.transform(val_imputed), columns=train_imputed.columns)\n",
    "\n",
    "dumb5 = pd.get_dummies(val['x5'], drop_first=True, prefix='x5', prefix_sep='_', dummy_na=True)\n",
    "val_imputed_std = pd.concat([val_imputed_std, dumb5], axis=1, sort=False)\n",
    "\n",
    "dumb31 = pd.get_dummies(val['x31'], drop_first=True, prefix='x31', prefix_sep='_', dummy_na=True)\n",
    "val_imputed_std = pd.concat([val_imputed_std, dumb31], axis=1, sort=False)\n",
    "\n",
    "dumb81 = pd.get_dummies(val['x81'], drop_first=True, prefix='x81', prefix_sep='_', dummy_na=True)\n",
    "val_imputed_std = pd.concat([val_imputed_std, dumb81], axis=1, sort=False)\n",
    "\n",
    "dumb82 = pd.get_dummies(val['x82'], drop_first=True, prefix='x82', prefix_sep='_', dummy_na=True)\n",
    "val_imputed_std = pd.concat([val_imputed_std, dumb82], axis=1, sort=False)\n",
    "val_imputed_std = pd.concat([val_imputed_std, val['y']], axis=1, sort=False)\n",
    "\n",
    "val_imputed_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = pd.DataFrame(imputer.transform(test.drop(columns=['y', 'x5', 'x31', 'x81' ,'x82'])), columns=train.drop(columns=['y','x5', 'x31', 'x81', 'x82']).columns)\n",
    "test_imputed_std = pd.DataFrame(std_scaler.transform(test_imputed), columns=train_imputed.columns)\n",
    "\n",
    "# 3 create dummies\n",
    "\n",
    "dumb5 = pd.get_dummies(test['x5'], drop_first=True, prefix='x5', prefix_sep='_', dummy_na=True)\n",
    "test_imputed_std = pd.concat([test_imputed_std, dumb5], axis=1, sort=False)\n",
    "\n",
    "dumb31 = pd.get_dummies(test['x31'], drop_first=True, prefix='x31', prefix_sep='_', dummy_na=True)\n",
    "test_imputed_std = pd.concat([test_imputed_std, dumb31], axis=1, sort=False)\n",
    "\n",
    "dumb81 = pd.get_dummies(test['x81'], drop_first=True, prefix='x81', prefix_sep='_', dummy_na=True)\n",
    "test_imputed_std = pd.concat([test_imputed_std, dumb81], axis=1, sort=False)\n",
    "\n",
    "dumb82 = pd.get_dummies(test['x82'], drop_first=True, prefix='x82', prefix_sep='_', dummy_na=True)\n",
    "test_imputed_std = pd.concat([test_imputed_std, dumb82], axis=1, sort=False)\n",
    "test_imputed_std = pd.concat([test_imputed_std, test['y']], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "       ...\n",
       "       'x81_June', 'x81_March', 'x81_May', 'x81_November', 'x81_October',\n",
       "       'x81_September', 'x81_nan', 'x82_Male', 'x82_nan', 'y'],\n",
       "      dtype='object', length=122)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_imputed_std.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The C-Statistics is  0.8011821329279427\n",
      "The C-Statistics is  0.7981369915910524\n",
      "The C-Statistics is  0.8021842765709619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prob_bin\n",
       "(0.0026, 0.0817]      29\n",
       "(0.0817, 0.128]      172\n",
       "(0.128, 0.172]       267\n",
       "(0.172, 0.216]       391\n",
       "(0.216, 0.26]        416\n",
       "(0.26, 0.303]        538\n",
       "(0.303, 0.348]       578\n",
       "(0.348, 0.395]       675\n",
       "(0.395, 0.44]        660\n",
       "(0.44, 0.487]        775\n",
       "(0.487, 0.531]       844\n",
       "(0.531, 0.577]       893\n",
       "(0.577, 0.621]       934\n",
       "(0.621, 0.667]      1011\n",
       "(0.667, 0.713]      1056\n",
       "(0.713, 0.759]      1162\n",
       "(0.759, 0.806]      1228\n",
       "(0.806, 0.854]      1344\n",
       "(0.854, 0.906]      1445\n",
       "(0.906, 0.995]      1577\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outcomes_train = pd.DataFrame(result.predict(train_imputed_std[variables])).rename(columns={0:'probs'})\n",
    "Outcomes_train['y'] = train_imputed_std['y']\n",
    "print('The C-Statistics is ',roc_auc_score(Outcomes_train['y'], Outcomes_train['probs']))\n",
    "Outcomes_val = pd.DataFrame(result.predict(val_imputed_std[variables])).rename(columns={0:'probs'})\n",
    "Outcomes_val['y'] = val_imputed_std['y']\n",
    "print('The C-Statistics is ',roc_auc_score(Outcomes_val['y'], Outcomes_val['probs']))\n",
    "Outcomes_test = pd.DataFrame(result.predict(test_imputed_std[variables])).rename(columns={0:'probs'})\n",
    "Outcomes_test['y'] = test_imputed_std['y']\n",
    "print('The C-Statistics is ',roc_auc_score(Outcomes_test['y'], Outcomes_test['probs']))\n",
    "Outcomes_train['prob_bin'] = pd.qcut(Outcomes_train['probs'], q=20)\n",
    "\n",
    "Outcomes_train.groupby(['prob_bin'])['y'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing the Model\n",
    "In the code above, we identified that the model generalized well; the AUC was similar for each of the partitions of the training data.  Moving forward, we want to \n",
    "1. refit the model using all of the training data\n",
    "2. check the coefficients against the preliminary model\n",
    "3. assess the lift and ask for a cutoff from the business partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536475\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 40000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 39975</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 13 Sep 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.2260</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:58:35</td>     <th>  Log-Likelihood:    </th> <td> -21459.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -27725.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_saturday</th>   <td>   -1.2065</td> <td>    0.037</td> <td>  -32.949</td> <td> 0.000</td> <td>   -1.278</td> <td>   -1.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_July</th>      <td>    1.0958</td> <td>    0.047</td> <td>   23.090</td> <td> 0.000</td> <td>    1.003</td> <td>    1.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_December</th>  <td>    1.0294</td> <td>    0.047</td> <td>   21.812</td> <td> 0.000</td> <td>    0.937</td> <td>    1.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_japan</th>     <td>    0.9249</td> <td>    0.056</td> <td>   16.540</td> <td> 0.000</td> <td>    0.815</td> <td>    1.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_October</th>   <td>    0.9111</td> <td>    0.047</td> <td>   19.516</td> <td> 0.000</td> <td>    0.820</td> <td>    1.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_sunday</th>     <td>   -0.8573</td> <td>    0.036</td> <td>  -23.921</td> <td> 0.000</td> <td>   -0.928</td> <td>   -0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_asia</th>      <td>   -0.7595</td> <td>    0.030</td> <td>  -25.522</td> <td> 0.000</td> <td>   -0.818</td> <td>   -0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_February</th>  <td>    0.8253</td> <td>    0.047</td> <td>   17.645</td> <td> 0.000</td> <td>    0.734</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>           <td>    0.7660</td> <td>    0.013</td> <td>   60.549</td> <td> 0.000</td> <td>    0.741</td> <td>    0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_May</th>       <td>    0.7930</td> <td>    0.047</td> <td>   16.837</td> <td> 0.000</td> <td>    0.701</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_monday</th>     <td>   -0.6696</td> <td>    0.035</td> <td>  -18.935</td> <td> 0.000</td> <td>   -0.739</td> <td>   -0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_September</th> <td>    0.6814</td> <td>    0.047</td> <td>   14.630</td> <td> 0.000</td> <td>    0.590</td> <td>    0.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_March</th>     <td>    0.6835</td> <td>    0.047</td> <td>   14.664</td> <td> 0.000</td> <td>    0.592</td> <td>    0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>           <td>   -0.6221</td> <td>    0.012</td> <td>  -50.365</td> <td> 0.000</td> <td>   -0.646</td> <td>   -0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_November</th>  <td>    0.5608</td> <td>    0.047</td> <td>   12.039</td> <td> 0.000</td> <td>    0.470</td> <td>    0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>           <td>   -0.5058</td> <td>    0.012</td> <td>  -41.482</td> <td> 0.000</td> <td>   -0.530</td> <td>   -0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_June</th>      <td>    0.4448</td> <td>    0.047</td> <td>    9.537</td> <td> 0.000</td> <td>    0.353</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>           <td>   -0.3938</td> <td>    0.012</td> <td>  -32.788</td> <td> 0.000</td> <td>   -0.417</td> <td>   -0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5_tuesday</th>    <td>   -0.3727</td> <td>    0.035</td> <td>  -10.505</td> <td> 0.000</td> <td>   -0.442</td> <td>   -0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_August</th>    <td>    0.4300</td> <td>    0.047</td> <td>    9.162</td> <td> 0.000</td> <td>    0.338</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81_January</th>   <td>    0.3457</td> <td>    0.047</td> <td>    7.373</td> <td> 0.000</td> <td>    0.254</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>           <td>   -0.2882</td> <td>    0.012</td> <td>  -23.503</td> <td> 0.000</td> <td>   -0.312</td> <td>   -0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31_germany</th>   <td>   -0.1664</td> <td>    0.029</td> <td>   -5.649</td> <td> 0.000</td> <td>   -0.224</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>           <td>    0.2107</td> <td>    0.012</td> <td>   17.516</td> <td> 0.000</td> <td>    0.187</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>           <td>    0.2002</td> <td>    0.012</td> <td>   16.356</td> <td> 0.000</td> <td>    0.176</td> <td>    0.224</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                40000\n",
       "Model:                          Logit   Df Residuals:                    39975\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Tue, 13 Sep 2022   Pseudo R-squ.:                  0.2260\n",
       "Time:                        20:58:35   Log-Likelihood:                -21459.\n",
       "converged:                       True   LL-Null:                       -27725.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "x5_saturday      -1.2065      0.037    -32.949      0.000      -1.278      -1.135\n",
       "x81_July          1.0958      0.047     23.090      0.000       1.003       1.189\n",
       "x81_December      1.0294      0.047     21.812      0.000       0.937       1.122\n",
       "x31_japan         0.9249      0.056     16.540      0.000       0.815       1.035\n",
       "x81_October       0.9111      0.047     19.516      0.000       0.820       1.003\n",
       "x5_sunday        -0.8573      0.036    -23.921      0.000      -0.928      -0.787\n",
       "x31_asia         -0.7595      0.030    -25.522      0.000      -0.818      -0.701\n",
       "x81_February      0.8253      0.047     17.645      0.000       0.734       0.917\n",
       "x91               0.7660      0.013     60.549      0.000       0.741       0.791\n",
       "x81_May           0.7930      0.047     16.837      0.000       0.701       0.885\n",
       "x5_monday        -0.6696      0.035    -18.935      0.000      -0.739      -0.600\n",
       "x81_September     0.6814      0.047     14.630      0.000       0.590       0.773\n",
       "x81_March         0.6835      0.047     14.664      0.000       0.592       0.775\n",
       "x53              -0.6221      0.012    -50.365      0.000      -0.646      -0.598\n",
       "x81_November      0.5608      0.047     12.039      0.000       0.470       0.652\n",
       "x44              -0.5058      0.012    -41.482      0.000      -0.530      -0.482\n",
       "x81_June          0.4448      0.047      9.537      0.000       0.353       0.536\n",
       "x12              -0.3938      0.012    -32.788      0.000      -0.417      -0.370\n",
       "x5_tuesday       -0.3727      0.035    -10.505      0.000      -0.442      -0.303\n",
       "x81_August        0.4300      0.047      9.162      0.000       0.338       0.522\n",
       "x81_January       0.3457      0.047      7.373      0.000       0.254       0.438\n",
       "x62              -0.2882      0.012    -23.503      0.000      -0.312      -0.264\n",
       "x31_germany      -0.1664      0.029     -5.649      0.000      -0.224      -0.109\n",
       "x58               0.2107      0.012     17.516      0.000       0.187       0.234\n",
       "x56               0.2002      0.012     16.356      0.000       0.176       0.224\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_val = pd.concat([train_imputed_std, val_imputed_std])\n",
    "all_train = pd.concat([train_and_val, test_imputed_std])\n",
    "variables = var_reduced['name'].to_list()\n",
    "final_logit = sm.Logit(all_train['y'], all_train[variables])\n",
    "# fit the model\n",
    "final_result = final_logit.fit()\n",
    "final_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The C-Statistics is  0.8010042026368287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prob_bin\n",
       "(0.0026, 0.0824]      43\n",
       "(0.0824, 0.128]      206\n",
       "(0.128, 0.172]       317\n",
       "(0.172, 0.215]       479\n",
       "(0.215, 0.259]       517\n",
       "(0.259, 0.303]       674\n",
       "(0.303, 0.348]       732\n",
       "(0.348, 0.394]       835\n",
       "(0.394, 0.439]       836\n",
       "(0.439, 0.485]       949\n",
       "(0.485, 0.53]       1036\n",
       "(0.53, 0.575]       1102\n",
       "(0.575, 0.62]       1184\n",
       "(0.62, 0.666]       1261\n",
       "(0.666, 0.712]      1330\n",
       "(0.712, 0.758]      1438\n",
       "(0.758, 0.805]      1530\n",
       "(0.805, 0.854]      1658\n",
       "(0.854, 0.906]      1804\n",
       "(0.906, 0.995]      1973\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outcomes_train_final = pd.DataFrame(result.predict(all_train[variables])).rename(columns={0:'probs'})\n",
    "Outcomes_train_final['y'] = all_train['y']\n",
    "print('The C-Statistics is ',roc_auc_score(Outcomes_train_final['y'], Outcomes_train_final['probs']))\n",
    "Outcomes_train_final['prob_bin'] = pd.qcut(Outcomes_train_final['probs'], q=20)\n",
    "Outcomes_train_final.groupby(['prob_bin'])['y'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debrief\n",
    "In the final discussion with the business partner, the partner was thrilled with the rank-order ability of the model.  Based on a combination of capacity and accuracy, the partner would like to classify any observation that would fall in the top 5 bins as an event; for simplicity we will say the cutoff is at the 75th percentile.  For the API, please return the predicted outcome (variable name is business_outcome), predicted probability (variable name is phat), and all model inputs; the variables should be returned in alphabetical order in the API return."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
